---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.10.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import numpy as np
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import gensim
```

```{python}
from gensim import corpora,models
```

```{python}
stop = stopwords.words('english')
```

```{python}
a1 = pd.read_csv('content_reading1.csv',index_col=0)
a2 = pd.read_csv('content_reading2.csv',index_col=0)
a3 = pd.read_csv('content_reading3.csv',index_col=0)
a4 = pd.read_csv('content_reading4.csv',index_col=0)
```

```{python}
documents = pd.concat([a1,a2,a3,a4],ignore_index=True)
```

```{python}
documents = documents.drop_duplicates()
```

```{python}
documents
```

```{python}
documents['content'][5]
```

```{python}
documents['content'][16004]
```

```{python}
a = documents.duplicated()
```

```{python}
documents.index[a]
```

```{python}
documents.iloc[4005,:]
```

```{python}
documents.iloc[2535,:]
```

```{python}
corpus=[]
for doc in documents.content:
    text=re.sub('[^a-zA-z]',' ', doc)
    text=text.lower()
    text=text.split()
    text=[PorterStemmer().stem(word) for word in text if not word in stop]
    text=' '.join(text)
    corpus.append(text)
```

```{python}
documents['clean_content'] = corpus
```

```{python}
documents.head()
```

```{python}
processed_docs = documents.clean_content.str.split()
```

```{python}
processed_docs
```

```{python}
dictionary=gensim.corpora.Dictionary(processed_docs)
```

```{python}
count=0
for k,v in dictionary.iteritems():
    print(k,v)
    count+=1
    if count>20:
        break
```

```{python}
dictionary.filter_extremes(no_below=10,no_above=0.3,keep_n=1000)
```

```{python}
len(dictionary)
```

```{python}
dictionary[999]
```

```{python}
bow_corpus=[dictionary.doc2bow(doc) for doc in processed_docs]
```

```{python}
len(bow_corpus)
```

```{python}
bow_corpus_100=bow_corpus[100]
for i in range(len(bow_corpus_100)):
    print("Word {} (\"{}\") appears {} time.".format(bow_corpus_100[i][0], 
                                                     dictionary[bow_corpus_100[i][0]], 
                                                     bow_corpus_100[i][1]))
```

```{python}
tfidf=models.TfidfModel(bow_corpus)
```

```{python}
corpus_tfidf=tfidf[bow_corpus]
```

```{python}
corpus_tfidf[100]
```

### Model

```{python}
lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, 
                                             num_topics=4, 
                                             id2word = dictionary, 
                                             passes = 2, 
                                             workers=4)
```

```{python}
lda_model_tfidf.log_perplexity(bow_corpus)
```

```{python}
for idx, topic in lda_model_tfidf.print_topics(-1):
    print("Topic: {} Word: {}".format(idx, topic))
    print("\n")
```

```{python}
a = lda_model_tfidf[corpus_tfidf[100]]
a
```

```{python}
topic=[]
for i in range(len(corpus_tfidf)):
    a = lda_model_tfidf[corpus_tfidf[i]]
    a.sort(key=lambda x: x[1],reverse=True)
    topic.append([l[0] for l in a if l[1]>0.5])
```

```{python}
T = []
for t in topic:
    T.extend(t)
```

```{python}
for i in set(T):
    print(f'Topic {i} have {T.count(i)} times')
```

```{python}
hexagram,edit,last,move,relationship,mean,good
```
