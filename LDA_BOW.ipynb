{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import gensim\n",
    "from gensim import corpora,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pd.read_csv('content_reading1.csv',index_col=0)\n",
    "a2 = pd.read_csv('content_reading2.csv',index_col=0)\n",
    "a3 = pd.read_csv('content_reading3.csv',index_col=0)\n",
    "a4 = pd.read_csv('content_reading4.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.concat([a1,a2,a3,a4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There are some lovely people here who'll help you understand your reading. Here's how you can make it easier for them to help you:Share...some background and context for your reading - enough for people to understand what it's about.the question you asked, word for word.the answer Yi gave. (Our favourite format is like this: '27.2.5 to 61'.)your own feelings and thoughts about the answer.And ask for feedback!Then when you've read people's responses, please share your thoughts and update people on how it plays out. If you've browsed/searched the archives here you will know that these updates are what really make the forum a treasure - and besides, it's a kindness to the people who responded to you.Please don't miss out step 4! As Trojina said (emphasis added), Trojina said:As you say what you think and feel it opens the gates to the reading as it were. The reading is addressed to your mind so if you share your sense of the reading, the reading is actually more open for everyone to get a feel for it. No experience is needed to do this. All you have to do is read the text and the lines and just write down what comes to mind in how it might relate to your situation.Click to expand...Update:A further request/ suggestion: if you phrase your thread title as 'Question: reading' (eg 'What if I contact him? 59.6>29') then this will make it a) easier for people to see if they have an idea that can help you and b) more useful in the hexagram search results pages.Thank you!Last edited: Aug 2, 2018\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for doc in documents.content:\n",
    "    text=re.sub('[^a-zA-z]',' ', doc)\n",
    "    text=text.lower()\n",
    "    text=text.split()\n",
    "    text=[PorterStemmer().stem(word) for word in text if not word in stop]\n",
    "    text=' '.join(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents['clean_content'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents.clean_content.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 actual\n",
      "1 ad\n",
      "2 address\n",
      "3 answer\n",
      "4 archiv\n",
      "5 ask\n",
      "6 aug\n",
      "7 b\n",
      "8 background\n",
      "9 besid\n",
      "10 brows\n",
      "11 click\n",
      "12 come\n",
      "13 contact\n",
      "14 context\n",
      "15 easier\n",
      "16 edit\n",
      "17 eg\n",
      "18 emphasi\n",
      "19 enough\n",
      "20 everyon\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for k,v in dictionary.iteritems():\n",
    "    print(k,v)\n",
    "    count+=1\n",
    "    if count>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=3,no_above=0.3,keep_n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus=[dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 3\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=bow_corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.4335224022190705"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_perplexity(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.030*\"yi\" + 0.023*\"comment\" + 0.018*\"receiv\" + 0.018*\"answer\" + 0.018*\"interpret\" + 0.018*\"want\" + 0.017*\"thought\" + 0.017*\"move\" + 0.017*\"ignor\" + 0.017*\"correct\"\n",
      "\n",
      "\n",
      "Topic: 1 Word: 0.010*\"hexagram\" + 0.008*\"want\" + 0.008*\"relationship\" + 0.008*\"say\" + 0.008*\"work\" + 0.008*\"realli\" + 0.008*\"seem\" + 0.007*\"good\" + 0.007*\"mean\" + 0.007*\"hex\"\n",
      "\n",
      "\n",
      "Topic: 2 Word: 0.029*\"hex\" + 0.029*\"discuss\" + 0.029*\"approach\" + 0.019*\"imag\" + 0.018*\"difficulti\" + 0.018*\"begin\" + 0.017*\"right\" + 0.017*\"life\" + 0.017*\"stay\" + 0.014*\"superior\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in model.print_topics(-1):\n",
    "    print(\"Topic: {} Word: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=[]\n",
    "for i in range(len(bow_corpus)):\n",
    "    a = model[bow_corpus[i]]\n",
    "    a.sort(key=lambda x: x[1],reverse=True)\n",
    "    topic.append([l[0] for l in a if l[1]>0.1])\n",
    "\n",
    "T = []\n",
    "for t in topic:\n",
    "    T.extend(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 have 1646 times\n",
      "Topic 1 have 15973 times\n",
      "Topic 2 have 917 times\n"
     ]
    }
   ],
   "source": [
    "for i in set(T):\n",
    "    print(f'Topic {i} have {T.count(i)} times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
